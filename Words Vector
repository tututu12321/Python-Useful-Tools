import random
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from sklearn.decomposition import PCA

def train_word2vec_model(texts, vector_size=100, window=5, min_count=1):
    """
    Word2Vecモデルの構築
    texts: 入力テキストのリスト（単語リストのリスト形式）
    vector_size: ベクトルの次元数
    window: 文脈サイズ
    min_count: 学習に必要な最小出現回数
    """
    model = Word2Vec(sentences=texts, vector_size=vector_size, window=window, min_count=min_count, workers=4)
    return model

def plot_word_vectors(model, words=None):
    """
    学習したWord2Vecモデルの単語ベクトルを2Dにプロット
    model: 学習済みWord2Vecモデル
    words: プロットしたい単語のリスト
    """
    if words is None:
        words = list(model.wv.index_to_key)  # モデルに存在するすべての単語を使用
    
    # モデルに含まれていない単語は除外
    words = [word for word in words if word in model.wv]

    if len(words) == 0:
        print("None of the words are in the model's vocabulary.")
        return

    # 単語ベクトルを取得
    word_vectors = [model.wv[word] for word in words]
    
    # PCAで2次元に縮約
    pca = PCA(n_components=2)
    reduced_vectors = pca.fit_transform(word_vectors)

    # プロット
    plt.figure(figsize=(10, 10))
    for i, word in enumerate(words):
        plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1])
        plt.text(reduced_vectors[i, 0] + 0.01, reduced_vectors[i, 1] + 0.01, word, fontsize=12)
    
    plt.title("Word2Vec - Word Embeddings")
    plt.show()

# --- 実行例 ---
if __name__ == "__main__":
    # サンプルテキスト（簡単なテキストデータ）
    sample_text = """
    I love programming in Python. Python is great for machine learning and data science.
    I also enjoy learning new languages, especially English, which is fun to practice.
    """

    # テキストを単語リストに分割
    texts = [sentence.split() for sentence in sample_text.split(".") if sentence.strip()]

    # Word2Vecモデルを構築
    word2vec_model = train_word2vec_model(texts)

    # 特定の単語をプロット
    words_to_plot = ["Python", "programming", "machine", "learning", "data", "science", "English"]
    plot_word_vectors(word2vec_model, words=words_to_plot)
